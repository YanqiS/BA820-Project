## **Problem Statement & Motivations**
Airbnb, a leading lodging platform with millions of unique listings worldwide, captures our interest as Boston University students, particularly for its Boston area listings. Our project aims to tackle challenges of deciphering the factors that contribute to a listing's success and understanding the natural grouping using unsupervised machine learning. By analyzing the extensive and diverse dataset, we seek to uncover patterns and trends that can inform better decision-making for hosts and improve the overall experience for customers.

##**Dataset**
Dataset Source: http://insideairbnb.com/get-the-data/
We will be using “Listings” and “Reviews” tables from the Boston data section on the website, providing a thorough overview of Boston's Airbnb listings. It includes information on accommodation types, prices, descriptions, and reviews in addition to geographic data.


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

# df_listings = pd.read_csv('/content/drive/MyDrive/DataSet/listings.csv')
# df_reviews = pd.read_csv('/content/drive/MyDrive/DataSet/reviews.csv')

df_listings = pd.read_csv('/content/listings.csv')
df_reviews = pd.read_csv('/content/reviews.csv')
# df_listings = pd.read_csv('/content/drive/MyDrive/listings.csv')
# df_reviews = pd.read_csv('/content/drive/MyDrive/reviews.csv')

for data in [df_listings,df_reviews]:
    display(data)
    print(data.shape)

df_reviews.info()

df_listings.info()

df_reviews.isnull().sum()

df_reviews.dropna(inplace = True)

df_reviews.isnull().sum()

df_listings.describe(include='all')

missing_data = df_listings.isnull().sum()
missing_percentage = (missing_data / len(df_listings)) * 100

missing_df = pd.DataFrame({'missing_count': missing_data, 'missing_percentage': missing_percentage})
missing_df[missing_df['missing_count'] > 0].sort_values(by='missing_percentage', ascending=False)

df_listings.drop(columns=['description', 'bathrooms', 'calendar_updated', 'bedrooms', 'neighbourhood_group_cleansed'], inplace=True)

df_listings.drop(df_listings.columns[df_listings.columns.str.contains("url")],axis=1,inplace=True)

df_listings.drop(columns=['calculated_host_listings_count_shared_rooms','minimum_minimum_nights','maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','host_location','amenities','host_name','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms','host_listings_count','host_total_listings_count','number_of_reviews_ltm','number_of_reviews_l30d','last_scraped','source','availability_30','availability_60','availability_90','calendar_last_scraped'], inplace=True)

df_listings['bathrooms'] = df_listings['bathrooms_text'].str.extract(r'(\d+\.?\d*)')[0].astype(float)
df_listings.loc[df_listings['bathrooms_text'].str.contains('half', na=False), 'bathrooms'] = 0.5 #

df_listings.drop(columns=['bathrooms_text'],inplace=True)

df_listings.drop(columns=['description', 'bathrooms', 'calendar_updated', 'bedrooms', 'neighbourhood_group_cleansed'], inplace=True)

df_listings.drop(df_listings.columns[df_listings.columns.str.contains("url")],axis=1,inplace=True)

df_listings.drop(columns=['calculated_host_listings_count_shared_rooms','minimum_minimum_nights','maximum_minimum_nights','minimum_maximum_nights','maximum_maximum_nights','host_location','amenities','host_name','calculated_host_listings_count_entire_homes','calculated_host_listings_count_private_rooms','calculated_host_listings_count_shared_rooms','host_listings_count','host_total_listings_count','number_of_reviews_ltm','number_of_reviews_l30d','last_scraped','source','availability_30','availability_60','availability_90','calendar_last_scraped'], inplace=True)

df_listings['bathrooms'] = df_listings['bathrooms_text'].str.extract(r'(\d+\.?\d*)')[0].astype(float)
df_listings.loc[df_listings['bathrooms_text'].str.contains('half', na=False), 'bathrooms'] = 0.5 #

df_listings.drop(columns=['bathrooms_text'],inplace=True)
